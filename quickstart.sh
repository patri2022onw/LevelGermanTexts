#!/bin/bash
# quickstart.sh - Quick setup script for German Language Analyzer

echo "ğŸ‡©ğŸ‡ª German Language Analyzer - Quick Start Setup"
echo "=============================================="

# Check Python version
echo -e "\nğŸ“ Checking Python version..."
python_version=$(python3 --version 2>&1)
if [[ $? -eq 0 ]]; then
    echo "âœ… Found: $python_version"
else
    echo "âŒ Python 3 not found. Please install Python 3.8 or higher."
    exit 1
fi

# Create virtual environment
echo -e "\nğŸ“ Creating virtual environment..."
if [ ! -d "venv" ]; then
    python3 -m venv venv
    echo "âœ… Virtual environment created"
else
    echo "â„¹ï¸  Virtual environment already exists"
fi

# Activate virtual environment
echo -e "\nğŸ“ Activating virtual environment..."
source venv/bin/activate || . venv/Scripts/activate
echo "âœ… Virtual environment activated"

# Install requirements
echo -e "\nğŸ“ Installing requirements..."
pip install --upgrade pip
pip install -r requirements.txt
echo "âœ… Requirements installed"

# Verify spaCy model installation
echo -e "\nğŸ“ Checking spaCy NER model..."
python -c "
try:
    import spacy
    nlp = spacy.load('de_core_news_sm')
    print('âœ… spaCy German NER model (de_core_news_sm) loaded successfully')
except ImportError:
    print('âš ï¸  spaCy not installed - using fallback NER')
except OSError:
    print('âš ï¸  spaCy model not found, downloading de_core_news_sm...')
    import subprocess
    subprocess.check_call(['python', '-m', 'spacy', 'download', 'de_core_news_sm'])
    print('âœ… spaCy model downloaded')
"

# Note: Simplemma is dependency-free
echo -e "\nğŸ“ Simplemma setup..."
echo "âœ… Simplemma is ready to use (no model download required)"

# Create directories if needed
echo -e "\nğŸ“ Setting up project structure..."
mkdir -p .streamlit
mkdir -p logs
mkdir -p output
echo "âœ… Directories created"

# Check for vocabulary files
echo -e "\nğŸ“ Checking vocabulary files..."
python check_files.py

# Create example secrets file if it doesn't exist
if [ ! -f ".streamlit/secrets.toml" ]; then
    echo -e "\nğŸ“ Creating example secrets file..."
    cat > .streamlit/secrets.toml << 'EOF'
# Example secrets file - Add your actual API keys here
[api_keys]
# claude_api_key = "your-claude-api-key"
# gemini_api_key = "your-gemini-api-key"
# deepl_api_key = "your-deepl-api-key"

[deployment]
environment = "development"
EOF
    echo "âœ… Created .streamlit/secrets.toml (add your API keys)"
fi

# Final instructions
echo -e "\nâœ¨ Setup complete!"
echo -e "\nğŸ“‹ Next steps:"
echo "1. Add your vocabulary files (A1.csv, A2.csv, etc.) to the vocabulary/ directory"
echo "2. Add your API keys to .streamlit/secrets.toml (optional)"
echo "3. Run the app with: streamlit run app.py"
echo -e "\nğŸ’¡ Features:"
echo "   - Uses simplemma for fast, dependency-free German lemmatization"
echo "   - Uses spaCy with de_core_news_sm for named entity recognition"
echo "   - Falls back to enhanced heuristic NER if spaCy not available"
echo "   - Optimized for Python 3.13 compatibility"
echo "   - Supports Claude and Gemini AI integration"
echo -e "\nğŸ’¡ For deployment on Streamlit Cloud:"
echo "   - Push all files to GitHub"
echo "   - Deploy at share.streamlit.io"
echo "   - Configure secrets in the Streamlit Cloud dashboard"